---
layout: single
title: "Frequency Attention for Knowledge Distillation
(WACV 2024)"
date: "2025-02-05"
comments: "true"
use_math: true
categories: 
  - Paper-Review
sitemap:
  changefreq: daily
  priority : 1.0
---

# Frequency Attention for Knowledge Distillation - 논문 리뷰

## 📌 목차

1. [서론](#-1-서론)
2. [관련 연구](#-2-관련-연구-related-work)
3. [제안 방법](#-3-제안-방법-proposed-method)
4. [실험 결과](#-4-실험-결과-experiments)
5. [결론 및 한계점](#-5-결론-및-한계점)
6. [추가 질문 및 토론](#-6-추가-질문-및-토론)

## 📌 논문 정보
- **제목**: Frequency Attention for Knowledge Distillation
- **저자**: Cuong Pham, Van-Anh Nguyen, Trung Le, Dinh Phung, Gustavo Carneiro, Thanh-Toan Do
- **학회**: WACV 2024

---

## 📌 1. 서론
### ✅ 연구 배경
- **지식 증류(Knowledge Distillation, KD)** 는 크고 복잡한 Teacher 모델의 정보를 작은 Student 모델에 전달하는 방법.
- 기존 KD 기법에서는 **공간 영역(Spatial Domain)에서의 Attention** 을 활용하여 중요한 Feature를 강조.
- 하지만, **공간 기반 Attention은 전역(Global) 정보가 부족**하여 효과적인 Knowledge Transfer에 한계가 있음.
- **주파수 도메인(Frequency Domain)은 전체 픽셀을 고려하여 전역 정보 포함**할 수 있음.

### ✅ 연구 목표
- **주파수 도메인에서 동작하는 Frequency Attention Module (FAM) 제안**.
- **FAM을 Layer-to-Layer KD 및 Knowledge Review KD에 적용하여 성능 향상**.
- 다양한 데이터셋에서 성능을 검증.

---

## 📌 2. 관련 연구 (Related Work)
### 🔹 기존 KD 기법
1. **Logit 기반 KD**: Softmax 출력을 정제하여 distillation 수행 (Hinton et al., 2014).
2. **Feature 기반 KD**: 중간 feature map을 활용한 KD (FitNets, ReviewKD 등).
3. **Attention 기반 KD**: 공간 기반 Attention을 활용하여 중요한 정보 강조 (AT, AFD 등).

### 🔹 기존 공간 기반 Attention의 한계
- 공간 도메인에서 Attention을 적용하면 **국소(Local) 정보만 강조됨**.
- **전역(Global) 구조 정보 부족** → Teacher의 중요한 정보를 효과적으로 반영하기 어려움.
- 공간 기반 Attention의 예:
  - AT(Attention Transfer) (Zagoruyko & Komodakis, 2017)
  - AFD(Attention Feature Distillation) (Ji et al., 2021)

### 🔹 주파수 기반 Attention의 필요성
- **이미지에서 주파수란?**
  - 공간적 픽셀 간의 관계를 분석하여 **변화율(Gradient Difference)로 주파수를 측정**.
  - **저주파(Low Frequency)**: 부드러운 색 변화, 배경 정보
  - **고주파(High Frequency)**: 경계(Edge), 텍스처(Texture), 작은 구조들
- 기존 공간 기반 Attention과 달리, 주파수 기반 분석을 통해 **전역적인 패턴을 학습할 수 있음**.

---

## 📌 3. 제안 방법 (Proposed Method)
### 🔹 Frequency Attention Module (FAM)
- FAM은 **전역(Global) 및 국소(Local) branch** 로 구성됨.
- **전역 Branch (Global Branch)**
  - Fast Fourier Transform (FFT)를 사용하여 **공간 도메인 → 주파수 도메인 변환**.
  - Learnable Global Filter 를 통해 Teacher Feature를 반영.
  - **High Pass Filter (HPF) 적용 → 저주파 제거, 고주파 강조**.
  - Inverse FFT를 사용하여 다시 공간 도메인으로 변환.

\$\$
X(u, v) = \sum_{k=0}^{H-1} \sum_{l=0}^{W-1} X(k, l) e^{-i 2\pi \left( \frac{uk}{H} + \frac{vl}{W} \right)}
\$\$

- **국소 Branch (Local Branch)**
  - 1x1 Convolution을 활용하여 공간 정보를 보존.
  - 최종적으로 두 Branch를 **가중합하여 최적의 Feature 생성**.

### 🔹 Knowledge Distillation 적용 방식
1. **Layer-to-Layer KD**
   - Student 모델의 중간 Feature를 FAM을 통해 변환 후 Teacher Feature와 유사하게 학습.
   - **Local Self-Attention (LA)** 를 추가하여 공간 정보도 반영.

2. **Knowledge Review KD**
   - Teacher의 저수준(Low-level) Feature를 활용하여 Student의 심층 Feature를 보정.
   - **Cross-Attention을 적용하여 Feature Fusion 수행**.

---

## 📌 4. 실험 결과 (Experiments)
### 🔹 데이터셋 및 실험 설정
- **이미지 분류(Image Classification)**: CIFAR-100, ImageNet
- **객체 검출(Object Detection)**: MS COCO
- **Teacher-Student 모델**: ResNet50 → MobileNetV1, ResNet34 → ResNet18 등

### 🔹 주요 실험 결과
#### ✅ CIFAR-100
- Layer-to-Layer KD: 기존 기법보다 **Top-1 Accuracy 향상**.
- Knowledge Review KD: 기존 ReviewKD보다 **+1.34% 향상**.

#### ✅ ImageNet
- ResNet34 → ResNet18, ResNet50 → MobileNetV1 실험에서 **기존 SOTA 대비 1% 이상 성능 향상**.

#### ✅ MS COCO (객체 검출)
- Faster R-CNN + FPN 모델에서 FAM-KD 적용 시 **DKD + ReviewKD 대비 성능 향상**.

#### ✅ Ablation Study
- HPF 제거 시 성능 저하 → **HPF가 고주파 특징 강조에 중요한 역할 수행**.
- Global vs. Local Branch 비교 → **전역 Branch가 성능에 더 큰 기여**.


---

## 📌 5. 결론 및 한계점
### ✅ 결론
- **주파수 도메인에서 동작하는 새로운 Frequency Attention Module (FAM) 제안**.
- **기존 공간 기반 KD 대비 성능 향상 확인**.
- 다양한 Teacher-Student 모델에서 효과 검증.

### 🚀 한계점 및 향후 연구 방향
- **다양한 주파수 변환 기법 적용 가능** (예: 웨이블릿 변환).
- **Transformer 기반 모델과 결합하여 추가 실험 진행 필요**.

---

## 📌 6. 추가 질문 및 토론
### 🔹 질문 1: 이미지에서 주파수는 어떻게 결정될까?
✅ **주변 픽셀 간의 관계(Gradient Difference)에 따라 주파수가 결정됨**.

### 🔹 질문 2: 웨이블릿 변환 vs. 푸리에 변환 차이점은?
✅ 푸리에는 **전체 주파수 분석(전역)**, 웨이블릿은 **공간-주파수를 동시에 분석(지역적 정보 유지 가능)**.

### 🔹 질문 3: HPF(High Pass Filter)를 사용하면 어떤 이점이 있을까?
✅ **불필요한 배경 정보 제거, 객체 중심 Feature 강조, 경계 정보 보존** 등 여러 장점이 있음.


✍️ **Written by Bosung Baek**